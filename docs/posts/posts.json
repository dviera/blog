[
  {
    "path": "posts/2024-06-15-single-layer-perceptron-for-discrete-choice-model/",
    "title": "Single Layer Perceptron for Discrete Choice Model",
    "description": "Using a single layer perceptron to calculate the coefficients of a choice model and the willingness to pay. Compare the results with the Multinomial Logit Model.",
    "author": [
      {
        "name": "D.G.",
        "url": {}
      }
    ],
    "date": "2024-06-15",
    "categories": [],
    "contents": "\r\nA single layer perceptron with one neuron that receives a 2-dimensional array as input. This array represents the alternatives in the rows with features as columns. Many questions can be presented to each respondent showing different product alternatives every time. They have to choose one of them. The output is the probabilities for each row (alternative).\r\nInput Layer:\r\nInput: A 2D array where rows represent different alternatives and columns represent features.\r\nShape: (n_alternatives, n_features)\r\n\r\nSingle Neuron:\r\nThis neuron will compute a weighted sum of the input features without a bias term.\r\nActivation Function: Softmax (to output probabilities for each alternative).\r\n\r\nOutput:\r\nProbabilities for each alternative.\r\nShape: (n_alternatives,)\r\n\r\nMathematical Representation\r\nInput Layer:\r\nInput: A 2D array \\(\\mathbf{X}\\) of shape \\((m, n)\\), where \\(m\\) is the number of alternatives and \\(n\\) is the number of features.\r\nExample Input: \\(\\mathbf{X} = \\begin{bmatrix} x_{11} & x_{12} & \\cdots & x_{1n} \\\\ x_{21} & x_{22} & \\cdots & x_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{m1} & x_{m2} & \\cdots & x_{mn} \\end{bmatrix}\\)\r\n\r\nWeights and Bias:\r\nWeight vector \\(\\mathbf{w}\\) of size \\(n \\times 1\\).\r\n\r\nSingle Neuron Computation:\r\nFor each alternative \\(i\\), the input \\(\\mathbf{x}_i\\) (a row of the matrix \\(\\mathbf{X}\\)) is used to compute the weighted sum plus bias:\r\n\\[ z_i = \\mathbf{x}_i \\mathbf{w} + b \\]\r\nHere, \\(\\mathbf{x}_i\\) is \\(1 \\times n\\) and \\(\\mathbf{w}\\) is \\(n \\times 1\\), resulting in \\(z_i\\) being a scalar.\r\n\r\nSoftmax Activation:\r\nThe scores \\(z_i\\) are then passed through the softmax function to get the probabilities:\r\n\\[ p_i = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}} \\]\r\n\r\nCode snippet\r\nSimulated data set from [@chapman2015r]. Full code here.\r\n\r\nclass MLPChoice(nn.Module):\r\n    \"\"\"Some Information about MLPChoice\"\"\"\r\n    def __init__(self, n_chosen, n_features):\r\n        super(MLPChoice, self).__init__()\r\n        self.n_chosen = n_chosen # choose only 1 alternative of the 3\r\n        self.n_features = n_features\r\n        \r\n        self.hidden = nn.Sequential(\r\n            nn.Linear(in_features=self.n_features, out_features=self.n_chosen, bias=False),\r\n        )\r\n\r\n    def forward(self, x):\r\n        logits = self.hidden(x) # dim batch x 3 x 1\r\n        logits = logits.squeeze() # dim batch x 3\r\n\r\n        return logits\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-06-16T23:01:01-04:00",
    "input_file": "single-layer-perceptron-for-discrete-choice-model.knit.md"
  },
  {
    "path": "posts/2024-06-13-linearization-techniques-in-optimization-multiplication-of-binary-variables/",
    "title": "Linearization Techniques in Optimization: Multiplication of Binary Variables",
    "description": "Linearization technique for the multiplication of binary variables [@asghari2022transformation].",
    "author": [
      {
        "name": "D.G.",
        "url": {}
      }
    ],
    "date": "2024-06-13",
    "categories": [],
    "contents": "\r\nConsider two binary variables \\(x_i\\) with \\(i \\in \\{1,...,m\\}\\) and \\(y_j\\)\r\nwith \\(j \\in \\{1,...,n\\}\\). To linearize the term \\(x_i·y_j\\), which results\r\nfrom multiplying the binary variables, we replace it with an additional\r\nbinary variable:\r\n\\[z_{ij} = x_i·y_j, \\forall i \\in \\{1,...,m\\}, \\forall j \\in \\{1,...,n\\}\\].\r\nThe model including the non-linear term can be linearized by adding some\r\nnew constraints as follows:\r\n\\[z_{i_j} ≤ x_i, ∀i ∈ \\{1,...,m\\}, ∀j ∈ {\\{1,...,n}\\}\\tag{1}\\]\r\n\\[z_{ij} ≤ y_j, ∀i ∈ \\{1,...,m\\}, ∀j ∈ {\\{1,...,n}\\}\\tag{2}\\]\r\n\\[z_{ij} ≥ x_i + y_j − 1, ∀i ∈ \\{1,...,m\\}, ∀j ∈ {\\{1,...,n}\\} \\tag{3}\\]\r\n\\[z_{ij} ∈ {0, 1}, ∀i ∈ \\{1,...,m\\}, ∀j ∈ {\\{1,...,n}\\}\\tag{4}\\]\r\nApplication: Quadratic Assignment Problem (Nahmias and Olsen 2015)\r\nThe problem is to assign machines to locations. It could be to assign other types of facilities to locations. This problem, unlike the simple assignment problem, is that where I assign one facility will have an impact on the others because there are interactions between facilities such as the number of materials handling trips and the cost of making those trips. We would like to put close facilities that have a lot of interactions.\r\nModel\r\n\\[\\begin{align*}\r\n\r\n&\\text{$n$ = number of machines;}\\\\\r\n\r\n&\\text{$d_{jr}$ = cost of making a single materials handling trip from location $j$ to location $r$;}\\\\\r\n\r\n&\\text{$f_{ik}$ = mean number of trips per time period from machine $i$ to machine $k$;}\\\\\r\n\r\n&x_{ij} =\r\n\\begin{cases}\r\n      1 & \\text{if machine $i$ is assigned to location $j$}\\\\\r\n      0 & \\text{otherwise}\r\n\\end{cases}  \r\n    \r\n\\end{align*}\\]\r\n\\[\\begin{align}\r\n\r\n\\sum_{i=1}^n \\sum_{j=1}^n \\sum_{k=1}^n \\sum_{r=1}^n f_{ik} · d_{jr} · x_{ij} · x_{kr}\r\n\r\n\\\\\r\n\r\n\\sum_{i=1}^n x_{ij} = 1,  \\forall j = 1,...,n\r\n\r\n\\\\\r\n\r\n\\sum_{j=1}^n x_{ij} = 1,  \\forall i = 1,...,n\r\n\r\n\\\\\r\nx_{ij} \\space\\space binary, \\forall i = 1,...,n \\space\\space and \\space\\space \\forall j = 1,...,n\r\n\r\n\\end{align}\\]\r\nImplementation in Julia\r\nExample 10.20 from (Tompkins et al. 2010).\r\n\r\n\r\nusing JuMP\r\nusing CPLEX\r\n# using GLPK\r\n\r\nflow = [0 5 2 0\r\n    0 0 2 3\r\n    3 4 0 0\r\n    0 0 5 0]\r\n\r\ndistance = [0 5 10 4\r\n    4 0 6 7\r\n    8 5 0 5\r\n    6 6 5 0]\r\n\r\nnbFac, nbLoc = size(flow)\r\n\r\nmodel = Model(CPLEX.Optimizer)\r\n# model = Model(GLPK.Optimizer)\r\n\r\n@variable(model, x[1:nbFac, 1:nbLoc], Bin)\r\n\r\n# New binary variable to linearize\r\n@variable(model, z[1:nbFac, 1:nbLoc, 1:nbFac, 1:nbLoc], Bin)\r\n\r\nfor j in 1:nbLoc\r\n    @constraint(model, sum(x[i, j] for i in 1:nbFac) == 1)\r\nend\r\n\r\nfor i in 1:nbFac\r\n    @constraint(model, sum(x[i, j] for j in 1:nbLoc) == 1)\r\nend\r\n\r\n# Added constraints to linearize\r\nfor i in 1:nbFac\r\n    for j in 1:nbLoc\r\n        for k in 1:nbFac\r\n            for r in 1:nbLoc\r\n                @constraint(model, z[i, j, k, r] <= x[i, j])\r\n                @constraint(model, z[i, j, k, r] <= x[k, r])\r\n                @constraint(model, z[i, j, k, r] >= x[i, j] + x[k, r] - 1)\r\n            end\r\n        end\r\n    end\r\nend\r\n\r\n@objective(model, Min, sum(flow[i, k] * distance[j, r] * z[i, j, k, r] for i = 1:nbFac for j = 1:nbLoc for k = 1:nbFac for r = 1:nbLoc))\r\n\r\nprint(model)\r\n\r\noptimize!(model)\r\n\r\nobjective_value(model)\r\n\r\nvalue.(x)\r\n\r\n\r\n\r\n\r\nAsghari, Mohammad, Amir M Fathollahi-Fard, SMJ Mirzapour Al-E-Hashem, and Maxim A Dulebenets. 2022. “Transformation and Linearization Techniques in Optimization: A State-of-the-Art Survey.” Mathematics 10 (2): 283.\r\n\r\n\r\nNahmias, Steven, and Tava Lennon Olsen. 2015. Production and Operations Analysis. Waveland Press.\r\n\r\n\r\nTompkins, James A, John A White, Yavuz A Bozer, and Jose Mario Azaña Tanchoco. 2010. Facilities Planning. John Wiley & Sons.\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-06-15T23:00:11-04:00",
    "input_file": {}
  }
]
